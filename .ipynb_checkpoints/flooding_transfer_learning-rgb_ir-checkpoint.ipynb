{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "early-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viplab/pt-gpu/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-history",
   "metadata": {},
   "source": [
    "## Load flooding configuration file from local device or gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "toxic-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  worldfloods_demo_test\n",
      "{   'data_params': {   'batch_size': 32,\n",
      "                       'bucket_id': 'ml4cc_data_lake',\n",
      "                       'channel_configuration': 'all',\n",
      "                       'download': {'test': True, 'train': True, 'val': True},\n",
      "                       'filter_windows': {   'apply': False,\n",
      "                                             'threshold_clouds': 0.5,\n",
      "                                             'version': 'v1'},\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'num_workers': 4,\n",
      "                       'path_to_splits': 'worldfloods',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {'normalize': True},\n",
      "                       'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
      "                       'train_transformation': {'normalize': True},\n",
      "                       'window_size': [256, 256]},\n",
      "    'experiment_name': 'worldfloods_demo_test',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'early_stopping_patience': 4,\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'metric_monitor': 'val_dice_loss',\n",
      "                                               'model_type': 'linear',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   1.93445299,\n",
      "                                                                       36.60054169,\n",
      "                                                                       2.19400729]},\n",
      "                        'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
      "                        'model_version': 'v1',\n",
      "                        'test': True,\n",
      "                        'train': True},\n",
      "    'resume_from_checkpoint': False,\n",
      "    'seed': 12}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 'worldfloods_demo_test',\n",
       " 'seed': 12,\n",
       " 'model_params': {'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       "  'model_version': 'v1',\n",
       "  'hyperparameters': {'max_tile_size': 256,\n",
       "   'metric_monitor': 'val_dice_loss',\n",
       "   'channel_configuration': 'all',\n",
       "   'label_names': ['land', 'water', 'cloud'],\n",
       "   'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "   'model_type': 'linear',\n",
       "   'num_classes': 3,\n",
       "   'max_epochs': 10,\n",
       "   'val_every': 1,\n",
       "   'lr': 0.0001,\n",
       "   'lr_decay': 0.5,\n",
       "   'lr_patience': 2,\n",
       "   'early_stopping_patience': 4,\n",
       "   'num_channels': 13},\n",
       "  'train': True,\n",
       "  'test': True},\n",
       " 'data_params': {'loader_type': 'local',\n",
       "  'num_workers': 4,\n",
       "  'filter_windows': {'version': 'v1', 'threshold_clouds': 0.5, 'apply': False},\n",
       "  'download': {'train': True, 'val': True, 'test': True},\n",
       "  'bucket_id': 'ml4cc_data_lake',\n",
       "  'path_to_splits': 'worldfloods',\n",
       "  'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
       "  'input_folder': 'S2',\n",
       "  'target_folder': 'gt',\n",
       "  'batch_size': 32,\n",
       "  'window_size': [256, 256],\n",
       "  'channel_configuration': 'all',\n",
       "  'train_transformation': {'normalize': True},\n",
       "  'test_transformation': {'normalize': True}},\n",
       " 'resume_from_checkpoint': False,\n",
       " 'gpus': '0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "import pkg_resources\n",
    "\n",
    "# Set filepath to configuration files\n",
    "# config_fp = 'path/to/worldfloods_template.json'\n",
    "config_fp = pkg_resources.resource_filename(\"ml4floods\",\"models/configurations/worldfloods_template.json\")\n",
    "\n",
    "config = get_default_config(config_fp)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-scope",
   "metadata": {},
   "source": [
    "## Step 2: Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-edgar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'bgri',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 4},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.experiment_name = 'training_flooding_bgri'\n",
    "config.data_params.channel_configuration = 'bgri'\n",
    "config.model_params.hyperparameters.channel_configuration = 'bgri'\n",
    "config.model_params.hyperparameters.num_channels = 4\n",
    "config.data_params.bucket_id = \"\"\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scientific-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 194151  tiles\n",
      "val 1284  tiles\n",
      "test 11  tiles\n",
      "CPU times: user 1.46 s, sys: 1.45 s, total: 2.91 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from ml4floods.models.dataset_setup import get_dataset\n",
    "\n",
    "config.data_params.batch_size = 72 # control this depending on the space on your GPU!\n",
    "config.data_params.loader_type = 'local'\n",
    "config.data_params.path_to_splits = \"/mnt/d/Flooding/worldfloods_v1_0\" # local folder to download the data\n",
    "config.data_params.train_test_split_file = \"/mnt/d/Flooding/train_test_split_local.json\"\n",
    "\n",
    "config.data_params[\"download\"] = {\"train\": True, \"val\": True, \"test\": True} # download only test data\n",
    "# config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json\" # use this to train with all the data\n",
    "config.data_params.num_workers = 12\n",
    "\n",
    "# If files are not in config.data_params.path_to_splits this will trigger the download of the products.\n",
    "dataset = get_dataset(config.data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-harassment",
   "metadata": {},
   "source": [
    "## Verfify data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-driver",
   "metadata": {},
   "source": [
    "#### Verify training data\n",
    "Data format here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fallen-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2697\n"
     ]
    }
   ],
   "source": [
    "train_dl = dataset.train_dataloader()\n",
    "train_dl_iter = iter(train_dl)\n",
    "print(len(train_dl_iter))\n",
    "batch_train = next(train_dl_iter)\n",
    "\n",
    "# batch_train[\"image\"].shape, batch_train[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-spanking",
   "metadata": {},
   "source": [
    "Verify validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "injured-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "val_dl = dataset.val_dataloader()\n",
    "\n",
    "val_dl_iter = iter(val_dl)\n",
    "print(len(val_dl_iter))\n",
    "batch_val = next(val_dl_iter)\n",
    "\n",
    "# batch_val[\"image\"].shape, batch_val[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "significant-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "test_dl = dataset.test_dataloader()\n",
    "\n",
    "test_dl_iter = iter(test_dl)\n",
    "print(len(test_dl_iter))\n",
    "\n",
    "batch_test = next(test_dl_iter)\n",
    "# batch_test[\"image\"].shape, batch_test[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-electron",
   "metadata": {},
   "source": [
    "### Plot batch by using ml4flood model \n",
    "check detail here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31b26d6b-ecc5-4648-92f5-299b6099f321",
   "metadata": {},
   "source": [
    "from models import flooding_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flooding_model.plot_batch(batch_train[\"image\"])\n",
    "\n",
    "n_images=6\n",
    "fig, axs = plt.subplots(3,n_images, figsize=(18,10),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7279717-cfb1-4d20-a915-869d1ab3ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from models import flooding_model\n",
    "flooding_model = importlib.reload(flooding_model)\n",
    "\n",
    "# batch_train_rgb = flooding_model.batch_to_unnorm_rgb(batch_train[\"image\"])\n",
    "# # batch_train_rgb.shape\n",
    "# plt.imshow(batch_train_rgb[2])\n",
    "# plt.show()\n",
    "\n",
    "# batch_train_rgb_mask = flooding_model.batch_mask_to_rgb(batch_train[\"mask\"])\n",
    "# plt.imshow(batch_train_rgb_mask[2])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-cleanup",
   "metadata": {},
   "source": [
    "## Step 3: Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proud-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'bgri',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 4},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # folder to store the trained model (it will create a subfolder with the name of the experiment)\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colonial-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.model_folder = \"train_models\" \n",
    "os.makedirs(\"train_models\", exist_ok=True)\n",
    "config.model_params.test = False\n",
    "config.model_params.train = True\n",
    "config.model_params.hyperparameters.model_type = \"unet\" # Currently implemented: simplecnn, unet, linear\n",
    "config.model_params.hyperparameters.metric_monitor = 'val_iou_loss' #IoU Loss\n",
    "# config.model_params.hyperparameters.num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternative-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of channels:  4 , num of classes:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (dconv_down1): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dconv_up3): Sequential(\n",
       "    (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up2): Sequential(\n",
       "    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up1): Sequential(\n",
       "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from models.flooding_model import WorldFloodsModel, DistilledTrainingModel, WorldFloodsModel2, WorldFloodsModel1\n",
    "importlib.reload(flooding_model)\n",
    "simple_model_params = copy.deepcopy(config.model_params)\n",
    "simple_model_params['hyperparameters']['model_type']=\"unet_simple\"\n",
    "\n",
    "# model = DistilledTrainingModel(config.model_params, simple_model_params)\n",
    "model = WorldFloodsModel2(config.model_params) # Focal loss and IoU loss\n",
    "# model = WorldFloodsModel1(config.model_params) # Focal loss and Dice loss\n",
    "net = model.network\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c4307a4-d88a-417c-94aa-4dd145299a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module UNet is treated as a zero-op.\n",
      "UNet(\n",
      "  7.78 M, 100.000% Params, 42.51 GMac, 100.000% MACs, \n",
      "  (dconv_down1): Sequential(\n",
      "    39.3 k, 0.505% Params, 2.58 GMac, 6.078% MACs, \n",
      "    (0): Conv2d(2.37 k, 0.030% Params, 155.19 MMac, 0.365% MACs, 4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 4.19 MMac, 0.010% MACs, inplace=True)\n",
      "    (2): Conv2d(36.93 k, 0.474% Params, 2.42 GMac, 5.693% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 4.19 MMac, 0.010% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down2): Sequential(\n",
      "    221.44 k, 2.845% Params, 3.63 GMac, 8.544% MACs, \n",
      "    (0): Conv2d(73.86 k, 0.949% Params, 1.21 GMac, 2.846% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 2.1 MMac, 0.005% MACs, inplace=True)\n",
      "    (2): Conv2d(147.58 k, 1.896% Params, 2.42 GMac, 5.688% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 2.1 MMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down3): Sequential(\n",
      "    885.25 k, 11.373% Params, 3.63 GMac, 8.535% MACs, \n",
      "    (0): Conv2d(295.17 k, 3.792% Params, 1.21 GMac, 2.844% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 1.05 MMac, 0.002% MACs, inplace=True)\n",
      "    (2): Conv2d(590.08 k, 7.581% Params, 2.42 GMac, 5.686% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 1.05 MMac, 0.002% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down4): Sequential(\n",
      "    3.54 M, 45.480% Params, 3.63 GMac, 8.530% MACs, \n",
      "    (0): Conv2d(1.18 M, 15.162% Params, 1.21 GMac, 2.843% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 524.29 KMac, 0.001% MACs, inplace=True)\n",
      "    (2): Conv2d(2.36 M, 30.318% Params, 2.42 GMac, 5.684% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 524.29 KMac, 0.001% MACs, inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(0, 0.000% Params, 7.34 MMac, 0.017% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dconv_up3): Sequential(\n",
      "    2.36 M, 30.318% Params, 9.67 GMac, 22.742% MACs, \n",
      "    (0): Conv2d(1.77 M, 22.737% Params, 7.25 GMac, 17.052% MACs, 768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 1.05 MMac, 0.002% MACs, inplace=True)\n",
      "    (2): Conv2d(590.08 k, 7.581% Params, 2.42 GMac, 5.686% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 1.05 MMac, 0.002% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_up2): Sequential(\n",
      "    590.08 k, 7.581% Params, 9.67 GMac, 22.752% MACs, \n",
      "    (0): Conv2d(442.5 k, 5.685% Params, 7.25 GMac, 17.054% MACs, 384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 2.1 MMac, 0.005% MACs, inplace=True)\n",
      "    (2): Conv2d(147.58 k, 1.896% Params, 2.42 GMac, 5.688% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 2.1 MMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_up1): Sequential(\n",
      "    147.58 k, 1.896% Params, 9.68 GMac, 22.772% MACs, \n",
      "    (0): Conv2d(110.66 k, 1.422% Params, 7.25 GMac, 17.059% MACs, 192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 4.19 MMac, 0.010% MACs, inplace=True)\n",
      "    (2): Conv2d(36.93 k, 0.474% Params, 2.42 GMac, 5.693% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 4.19 MMac, 0.010% MACs, inplace=True)\n",
      "  )\n",
      "  (conv_last): Conv2d(195, 0.003% Params, 12.78 MMac, 0.030% MACs, 64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Computational complexity:       42.51 GMac\n",
      "Number of parameters:           7.78 M  \n"
     ]
    }
   ],
   "source": [
    "# Compuatation complexity of network\n",
    "from ptflops import get_model_complexity_info\n",
    "macs, params = get_model_complexity_info(net, (config.model_params.hyperparameters.num_channels, config.model_params.hyperparameters.max_tile_size, config.model_params.hyperparameters.max_tile_size), as_strings=True, print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seventh-stationery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrongan93\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/viplab/VipLabProjects/satellite-knowledge-distillation/wandb/run-20220921_051124-2bse9623</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/trongan93/satellite-knowledge-distillation/runs/2bse9623\" target=\"_blank\">resilient-durian-36</a></strong> to <a href=\"https://wandb.ai/trongan93/satellite-knowledge-distillation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viplab/pt-gpu/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "setup_weights_and_biases = True\n",
    "if setup_weights_and_biases:\n",
    "    import wandb\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "    # UNCOMMENT ON FIRST RUN TO LOGIN TO Weights and Biases (only needs to be done once)\n",
    "    wandb.login()\n",
    "    run = wandb.init()\n",
    "\n",
    "    # Specifies who is logging the experiment to wandb\n",
    "    config['wandb_entity'] = 'ml4floods'\n",
    "    # Specifies which wandb project to log to, multiple runs can exist in the same project\n",
    "    config['wandb_project'] = 'worldfloods-trongan-test'\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        name=config.experiment_name,\n",
    "        project=config.wandb_project, \n",
    "        entity=config.wandb_entity\n",
    "    )\n",
    "else:\n",
    "    wandb_logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "downtown-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained model will be stored in train_models/training_flooding_bgri\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "experiment_path = f\"{config.model_params.model_folder}/{config.experiment_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{experiment_path}/checkpoint\",\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_iou_loss',\n",
    "    mode='min',\n",
    "#     prefix=''\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_iou_loss',\n",
    "    patience=10,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "# monitor='val_iou_loss'\n",
    "# monitor='val_dice_loss'\n",
    "\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "print(f\"The trained model will be stored in {config.model_params.model_folder}/{config.experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "searching-charity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config.gpus = 2 # which gpu to use\n",
    "# config.gpus = None # to not use GPU\n",
    "config.model_params.hyperparameters.max_epochs = 40 # train for maximum 4 epochs\n",
    "\n",
    "trainer = Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    auto_lr_find=False,\n",
    "    benchmark=False,\n",
    "    max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "    check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "    strategy='dp',\n",
    "    accelerator='gpu',\n",
    "    devices=config.gpus\n",
    "    # resume_from_checkpoint='~/Projects/github/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=0-step=24269.ckpt'\n",
    ")\n",
    "# config\n",
    "# https://wandb.ai/wandb/wandb-lightning/reports/Multi-GPU-Training-Using-PyTorch-Lightning--VmlldzozMTk3NTk\n",
    "# resume_from_checkpoint='/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=39-step=161799.ckpt'\n",
    "# resume_from_checkpoint='~/Projects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=30-step=47026.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-india",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viplab/pt-gpu/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | UNet | 7.8 M \n",
      "---------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.134    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viplab/pt-gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|███████████████████████████████████▊| 2697/2715 [43:06<00:17,  1.04it/s, loss=0.984, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████████████▊| 2698/2715 [43:09<00:16,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████████████▊| 2699/2715 [43:10<00:15,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████████████▊| 2700/2715 [43:11<00:14,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████████████▊| 2701/2715 [43:13<00:13,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▊| 2702/2715 [43:14<00:12,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▊| 2703/2715 [43:15<00:11,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▊| 2704/2715 [43:16<00:10,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▊| 2705/2715 [43:17<00:09,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▉| 2706/2715 [43:18<00:08,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▉| 2707/2715 [43:19<00:07,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▉| 2708/2715 [43:20<00:06,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▉| 2709/2715 [43:21<00:05,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▉| 2710/2715 [43:22<00:04,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▉| 2711/2715 [43:23<00:03,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▉| 2712/2715 [43:25<00:02,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▉| 2713/2715 [43:26<00:01,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████▉| 2714/2715 [43:27<00:00,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████| 2715/2715 [43:28<00:00,  1.04it/s, loss=0.984, v_num=9623]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████| 2715/2715 [43:28<00:00,  1.04it/s, loss=0.984, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 2697: 'val_iou_loss' reached 0.29760 (best 0.29760), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=0-step=2697-v5.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99%|████████████████████████████████████▊| 2697/2715 [41:34<00:16,  1.08it/s, loss=1.03, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  99%|████████████████████████████████████▊| 2698/2715 [41:38<00:15,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1:  99%|████████████████████████████████████▊| 2699/2715 [41:39<00:14,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1:  99%|████████████████████████████████████▊| 2700/2715 [41:40<00:13,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1:  99%|████████████████████████████████████▊| 2701/2715 [41:41<00:12,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▊| 2702/2715 [41:42<00:12,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▊| 2703/2715 [41:43<00:11,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▊| 2704/2715 [41:44<00:10,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▊| 2705/2715 [41:45<00:09,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2706/2715 [41:46<00:08,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2707/2715 [41:47<00:07,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2708/2715 [41:48<00:06,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2709/2715 [41:49<00:05,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2710/2715 [41:50<00:04,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2711/2715 [41:51<00:03,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2712/2715 [41:53<00:02,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2713/2715 [41:54<00:01,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2714/2715 [41:54<00:00,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████████████████████| 2715/2715 [41:55<00:00,  1.08it/s, loss=1.03, v_num=9623]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████████████████████| 2715/2715 [41:55<00:00,  1.08it/s, loss=1.03, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 5394: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  99%|████████████████████████████████████▊| 2697/2715 [40:02<00:16,  1.12it/s, loss=1.01, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  99%|████████████████████████████████████▊| 2698/2715 [40:05<00:15,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2:  99%|████████████████████████████████████▊| 2699/2715 [40:07<00:14,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2:  99%|████████████████████████████████████▊| 2700/2715 [40:08<00:13,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2:  99%|████████████████████████████████████▊| 2701/2715 [40:09<00:12,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▊| 2702/2715 [40:10<00:11,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▊| 2703/2715 [40:11<00:10,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▊| 2704/2715 [40:12<00:09,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▊| 2705/2715 [40:13<00:08,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2706/2715 [40:14<00:08,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2707/2715 [40:15<00:07,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2708/2715 [40:16<00:06,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2709/2715 [40:17<00:05,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2710/2715 [40:18<00:04,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2711/2715 [40:20<00:03,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2712/2715 [40:21<00:02,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2713/2715 [40:22<00:01,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2714/2715 [40:23<00:00,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|█████████████████████████████████████| 2715/2715 [40:23<00:00,  1.12it/s, loss=1.01, v_num=9623]\u001b[A\n",
      "Epoch 2: 100%|█████████████████████████████████████| 2715/2715 [40:23<00:00,  1.12it/s, loss=1.01, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 8091: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:   1%|▍                                      | 27/2715 [00:25<42:34,  1.05it/s, loss=1.03, v_num=9623]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/viplab/pt-gpu/lib/python3.10/site-packages/wandb/vendor/watchdog/observers/api.py\", line 199, in run\n",
      "    self.dispatch_events(self.event_queue, self.timeout)\n",
      "  File \"/home/viplab/pt-gpu/lib/python3.10/site-packages/wandb/vendor/watchdog/observers/api.py\", line 368, in dispatch_events\n",
      "    handler.dispatch(event)\n",
      "  File \"/home/viplab/pt-gpu/lib/python3.10/site-packages/wandb/vendor/watchdog/events.py\", line 454, in dispatch\n",
      "    _method_map[event_type](event)\n",
      "  File \"/home/viplab/pt-gpu/lib/python3.10/site-packages/wandb/filesync/dir_watcher.py\", line 309, in _on_file_moved\n",
      "    del self._file_event_handlers[old_save_name]\n",
      "KeyError: 'media/images/mask/train_overlay_220_29ee205632106fe66b0a.mask.png'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  99%|███████████████████████████████████████▋| 2697/2715 [39:23<00:15,  1.14it/s, loss=1, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████████████▋| 2698/2715 [39:28<00:14,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████████████▊| 2699/2715 [39:29<00:14,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████████████▊| 2700/2715 [39:30<00:13,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████████████▊| 2701/2715 [39:31<00:12,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▊| 2702/2715 [39:33<00:11,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▊| 2703/2715 [39:34<00:10,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▊| 2704/2715 [39:35<00:09,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▊| 2705/2715 [39:36<00:08,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▊| 2706/2715 [39:37<00:07,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▉| 2707/2715 [39:38<00:07,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▉| 2708/2715 [39:39<00:06,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▉| 2709/2715 [39:40<00:05,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▉| 2710/2715 [39:41<00:04,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▉| 2711/2715 [39:42<00:03,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▉| 2712/2715 [39:43<00:02,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▉| 2713/2715 [39:44<00:01,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████▉| 2714/2715 [39:45<00:00,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|████████████████████████████████████████| 2715/2715 [39:46<00:00,  1.14it/s, loss=1, v_num=9623]\u001b[A\n",
      "Epoch 3: 100%|████████████████████████████████████████| 2715/2715 [39:46<00:00,  1.14it/s, loss=1, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 10788: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 4:  99%|███████████████████████████████████▊| 2697/2715 [39:41<00:15,  1.13it/s, loss=0.911, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████████▊| 2698/2715 [39:46<00:15,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████████▊| 2699/2715 [39:47<00:14,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████████▊| 2700/2715 [39:48<00:13,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████████▊| 2701/2715 [39:49<00:12,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▊| 2702/2715 [39:50<00:11,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▊| 2703/2715 [39:51<00:10,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▊| 2704/2715 [39:52<00:09,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▊| 2705/2715 [39:53<00:08,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2706/2715 [39:54<00:07,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2707/2715 [39:56<00:07,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2708/2715 [39:57<00:06,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2709/2715 [39:58<00:05,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2710/2715 [39:59<00:04,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2711/2715 [40:00<00:03,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2712/2715 [40:01<00:02,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2713/2715 [40:02<00:01,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2714/2715 [40:03<00:00,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|████████████████████████████████████| 2715/2715 [40:04<00:00,  1.13it/s, loss=0.911, v_num=9623]\u001b[A\n",
      "Epoch 4: 100%|████████████████████████████████████| 2715/2715 [40:04<00:00,  1.13it/s, loss=0.911, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 13485: 'val_iou_loss' reached 0.26540 (best 0.26540), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=4-step=13485.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  99%|███████████████████████████████████▊| 2697/2715 [39:45<00:15,  1.13it/s, loss=0.931, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████████▊| 2698/2715 [39:50<00:15,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████████▊| 2699/2715 [39:51<00:14,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████████▊| 2700/2715 [39:52<00:13,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████████▊| 2701/2715 [39:54<00:12,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▊| 2702/2715 [39:55<00:11,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▊| 2703/2715 [39:56<00:10,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▊| 2704/2715 [39:57<00:09,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▊| 2705/2715 [39:58<00:08,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2706/2715 [39:59<00:07,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2707/2715 [40:00<00:07,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2708/2715 [40:01<00:06,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2709/2715 [40:02<00:05,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2710/2715 [40:03<00:04,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2711/2715 [40:04<00:03,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2712/2715 [40:05<00:02,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2713/2715 [40:06<00:01,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2714/2715 [40:07<00:00,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|████████████████████████████████████| 2715/2715 [40:08<00:00,  1.13it/s, loss=0.931, v_num=9623]\u001b[A\n",
      "Epoch 5: 100%|████████████████████████████████████| 2715/2715 [40:08<00:00,  1.13it/s, loss=0.931, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 16182: 'val_iou_loss' reached 0.26149 (best 0.26149), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=5-step=16182.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  99%|███████████████████████████████████▊| 2697/2715 [40:03<00:16,  1.12it/s, loss=0.968, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  99%|███████████████████████████████████▊| 2698/2715 [40:06<00:15,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6:  99%|███████████████████████████████████▊| 2699/2715 [40:07<00:14,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6:  99%|███████████████████████████████████▊| 2700/2715 [40:08<00:13,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6:  99%|███████████████████████████████████▊| 2701/2715 [40:09<00:12,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▊| 2702/2715 [40:10<00:11,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▊| 2703/2715 [40:11<00:10,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▊| 2704/2715 [40:12<00:09,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▊| 2705/2715 [40:13<00:08,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2706/2715 [40:15<00:08,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2707/2715 [40:16<00:07,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2708/2715 [40:17<00:06,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2709/2715 [40:18<00:05,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2710/2715 [40:19<00:04,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2711/2715 [40:20<00:03,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2712/2715 [40:21<00:02,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2713/2715 [40:22<00:01,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2714/2715 [40:23<00:00,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|████████████████████████████████████| 2715/2715 [40:24<00:00,  1.12it/s, loss=0.968, v_num=9623]\u001b[A\n",
      "Epoch 6: 100%|████████████████████████████████████| 2715/2715 [40:24<00:00,  1.12it/s, loss=0.968, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 18879: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  99%|███████████████████████████████████▊| 2697/2715 [40:22<00:16,  1.11it/s, loss=0.933, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  99%|███████████████████████████████████▊| 2698/2715 [40:26<00:15,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7:  99%|███████████████████████████████████▊| 2699/2715 [40:27<00:14,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7:  99%|███████████████████████████████████▊| 2700/2715 [40:28<00:13,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7:  99%|███████████████████████████████████▊| 2701/2715 [40:29<00:12,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▊| 2702/2715 [40:31<00:11,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▊| 2703/2715 [40:32<00:10,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▊| 2704/2715 [40:33<00:09,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▊| 2705/2715 [40:34<00:08,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2706/2715 [40:35<00:08,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2707/2715 [40:36<00:07,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2708/2715 [40:37<00:06,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2709/2715 [40:38<00:05,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2710/2715 [40:39<00:04,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2711/2715 [40:40<00:03,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2712/2715 [40:41<00:02,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2713/2715 [40:42<00:01,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2714/2715 [40:43<00:00,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|████████████████████████████████████| 2715/2715 [40:44<00:00,  1.11it/s, loss=0.933, v_num=9623]\u001b[A\n",
      "Epoch 7: 100%|████████████████████████████████████| 2715/2715 [40:44<00:00,  1.11it/s, loss=0.933, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 21576: 'val_iou_loss' reached 0.25786 (best 0.25786), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=7-step=21576.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  99%|███████████████████████████████████▊| 2697/2715 [39:54<00:15,  1.13it/s, loss=0.901, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  99%|███████████████████████████████████▊| 2698/2715 [39:58<00:15,  1.13it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8:  99%|███████████████████████████████████▊| 2699/2715 [39:59<00:14,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8:  99%|███████████████████████████████████▊| 2700/2715 [40:00<00:13,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8:  99%|███████████████████████████████████▊| 2701/2715 [40:01<00:12,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▊| 2702/2715 [40:02<00:11,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▊| 2703/2715 [40:03<00:10,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▊| 2704/2715 [40:04<00:09,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▊| 2705/2715 [40:05<00:08,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2706/2715 [40:06<00:08,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2707/2715 [40:07<00:07,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2708/2715 [40:09<00:06,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2709/2715 [40:10<00:05,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2710/2715 [40:11<00:04,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2711/2715 [40:12<00:03,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2712/2715 [40:13<00:02,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2713/2715 [40:14<00:01,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2714/2715 [40:15<00:00,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|████████████████████████████████████| 2715/2715 [40:16<00:00,  1.12it/s, loss=0.901, v_num=9623]\u001b[A\n",
      "Epoch 8: 100%|████████████████████████████████████| 2715/2715 [40:16<00:00,  1.12it/s, loss=0.901, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 24273: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  99%|███████████████████████████████████▊| 2697/2715 [40:11<00:16,  1.12it/s, loss=0.921, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  99%|███████████████████████████████████▊| 2698/2715 [40:15<00:15,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9:  99%|███████████████████████████████████▊| 2699/2715 [40:16<00:14,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9:  99%|███████████████████████████████████▊| 2700/2715 [40:17<00:13,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9:  99%|███████████████████████████████████▊| 2701/2715 [40:18<00:12,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▊| 2702/2715 [40:19<00:11,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▊| 2703/2715 [40:21<00:10,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▊| 2704/2715 [40:22<00:09,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▊| 2705/2715 [40:23<00:08,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2706/2715 [40:24<00:08,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2707/2715 [40:25<00:07,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2708/2715 [40:26<00:06,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2709/2715 [40:27<00:05,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2710/2715 [40:28<00:04,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2711/2715 [40:29<00:03,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2712/2715 [40:31<00:02,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2713/2715 [40:32<00:01,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2714/2715 [40:33<00:00,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|████████████████████████████████████| 2715/2715 [40:34<00:00,  1.12it/s, loss=0.921, v_num=9623]\u001b[A\n",
      "Epoch 9: 100%|████████████████████████████████████| 2715/2715 [40:34<00:00,  1.12it/s, loss=0.921, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 26970: 'val_iou_loss' reached 0.24840 (best 0.24840), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=9-step=26970.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  99%|██████████████████████████████████▊| 2697/2715 [41:33<00:16,  1.08it/s, loss=0.868, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  99%|██████████████████████████████████▊| 2698/2715 [41:36<00:15,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10:  99%|██████████████████████████████████▊| 2699/2715 [41:38<00:14,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10:  99%|██████████████████████████████████▊| 2700/2715 [41:39<00:13,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10:  99%|██████████████████████████████████▊| 2701/2715 [41:40<00:12,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▊| 2702/2715 [41:41<00:12,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▊| 2703/2715 [41:42<00:11,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▊| 2704/2715 [41:43<00:10,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▊| 2705/2715 [41:44<00:09,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2706/2715 [41:45<00:08,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2707/2715 [41:46<00:07,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2708/2715 [41:47<00:06,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2709/2715 [41:48<00:05,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2710/2715 [41:50<00:04,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2711/2715 [41:51<00:03,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2712/2715 [41:52<00:02,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2713/2715 [41:53<00:01,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2714/2715 [41:54<00:00,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|███████████████████████████████████| 2715/2715 [41:55<00:00,  1.08it/s, loss=0.868, v_num=9623]\u001b[A\n",
      "Epoch 10: 100%|███████████████████████████████████| 2715/2715 [41:55<00:00,  1.08it/s, loss=0.868, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 29667: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  99%|██████████████████████████████████▊| 2697/2715 [41:42<00:16,  1.08it/s, loss=0.902, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  99%|██████████████████████████████████▊| 2698/2715 [41:46<00:15,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11:  99%|██████████████████████████████████▊| 2699/2715 [41:47<00:14,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11:  99%|██████████████████████████████████▊| 2700/2715 [41:48<00:13,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11:  99%|██████████████████████████████████▊| 2701/2715 [41:49<00:13,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▊| 2702/2715 [41:50<00:12,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▊| 2703/2715 [41:51<00:11,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▊| 2704/2715 [41:52<00:10,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▊| 2705/2715 [41:54<00:09,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▉| 2706/2715 [41:55<00:08,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▉| 2707/2715 [41:56<00:07,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▉| 2708/2715 [41:57<00:06,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▉| 2709/2715 [41:58<00:05,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▉| 2710/2715 [41:59<00:04,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▉| 2711/2715 [42:00<00:03,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▉| 2712/2715 [42:01<00:02,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▉| 2713/2715 [42:02<00:01,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████▉| 2714/2715 [42:03<00:00,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████| 2715/2715 [42:04<00:00,  1.08it/s, loss=0.902, v_num=9623]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████| 2715/2715 [42:04<00:00,  1.08it/s, loss=0.902, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 32364: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  99%|██████████████████████████████████▊| 2697/2715 [45:14<00:18,  1.01s/it, loss=0.913, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  99%|██████████████████████████████████▊| 2698/2715 [45:17<00:17,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12:  99%|██████████████████████████████████▊| 2699/2715 [45:18<00:16,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12:  99%|██████████████████████████████████▊| 2700/2715 [45:20<00:15,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12:  99%|██████████████████████████████████▊| 2701/2715 [45:21<00:14,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▊| 2702/2715 [45:22<00:13,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▊| 2703/2715 [45:23<00:12,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▊| 2704/2715 [45:24<00:11,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▊| 2705/2715 [45:25<00:10,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2706/2715 [45:26<00:09,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2707/2715 [45:27<00:08,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2708/2715 [45:28<00:07,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2709/2715 [45:29<00:06,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2710/2715 [45:30<00:05,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2711/2715 [45:32<00:04,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2712/2715 [45:33<00:03,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2713/2715 [45:34<00:02,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2714/2715 [45:35<00:01,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|███████████████████████████████████| 2715/2715 [45:36<00:00,  1.01s/it, loss=0.913, v_num=9623]\u001b[A\n",
      "Epoch 12: 100%|███████████████████████████████████| 2715/2715 [45:36<00:00,  1.01s/it, loss=0.913, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 35061: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 13:  99%|██████████████████████████████████▊| 2697/2715 [47:24<00:18,  1.05s/it, loss=0.935, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  99%|██████████████████████████████████▊| 2698/2715 [47:28<00:17,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13:  99%|██████████████████████████████████▊| 2699/2715 [47:29<00:16,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13:  99%|██████████████████████████████████▊| 2700/2715 [47:30<00:15,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13:  99%|██████████████████████████████████▊| 2701/2715 [47:31<00:14,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▊| 2702/2715 [47:32<00:13,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▊| 2703/2715 [47:34<00:12,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▊| 2704/2715 [47:35<00:11,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▊| 2705/2715 [47:36<00:10,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2706/2715 [47:37<00:09,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2707/2715 [47:38<00:08,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2708/2715 [47:39<00:07,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2709/2715 [47:40<00:06,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2710/2715 [47:41<00:05,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2711/2715 [47:42<00:04,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2712/2715 [47:43<00:03,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2713/2715 [47:44<00:02,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2714/2715 [47:45<00:01,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|███████████████████████████████████| 2715/2715 [47:47<00:00,  1.06s/it, loss=0.935, v_num=9623]\u001b[A\n",
      "Epoch 13: 100%|███████████████████████████████████| 2715/2715 [47:47<00:00,  1.06s/it, loss=0.935, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 37758: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  99%|██████████████████████████████████▊| 2697/2715 [47:07<00:18,  1.05s/it, loss=0.934, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  99%|██████████████████████████████████▊| 2698/2715 [47:10<00:17,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14:  99%|██████████████████████████████████▊| 2699/2715 [47:11<00:16,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14:  99%|██████████████████████████████████▊| 2700/2715 [47:12<00:15,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14:  99%|██████████████████████████████████▊| 2701/2715 [47:13<00:14,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▊| 2702/2715 [47:14<00:13,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▊| 2703/2715 [47:16<00:12,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▊| 2704/2715 [47:17<00:11,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▊| 2705/2715 [47:18<00:10,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2706/2715 [47:19<00:09,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2707/2715 [47:20<00:08,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2708/2715 [47:21<00:07,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2709/2715 [47:22<00:06,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2710/2715 [47:23<00:05,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2711/2715 [47:24<00:04,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2712/2715 [47:25<00:03,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2713/2715 [47:27<00:02,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2714/2715 [47:27<00:01,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|███████████████████████████████████| 2715/2715 [47:29<00:00,  1.05s/it, loss=0.934, v_num=9623]\u001b[A\n",
      "Epoch 14: 100%|███████████████████████████████████| 2715/2715 [47:29<00:00,  1.05s/it, loss=0.934, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 40455: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  99%|██████████████████████████████████▊| 2697/2715 [46:52<00:18,  1.04s/it, loss=0.886, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  99%|██████████████████████████████████▊| 2698/2715 [46:56<00:17,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15:  99%|██████████████████████████████████▊| 2699/2715 [46:57<00:16,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15:  99%|██████████████████████████████████▊| 2700/2715 [46:58<00:15,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15:  99%|██████████████████████████████████▊| 2701/2715 [46:59<00:14,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▊| 2702/2715 [47:00<00:13,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▊| 2703/2715 [47:01<00:12,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▊| 2704/2715 [47:02<00:11,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▊| 2705/2715 [47:03<00:10,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▉| 2706/2715 [47:04<00:09,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▉| 2707/2715 [47:06<00:08,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▉| 2708/2715 [47:07<00:07,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▉| 2709/2715 [47:08<00:06,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▉| 2710/2715 [47:09<00:05,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▉| 2711/2715 [47:10<00:04,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▉| 2712/2715 [47:11<00:03,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▉| 2713/2715 [47:12<00:02,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████▉| 2714/2715 [47:13<00:01,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████| 2715/2715 [47:14<00:00,  1.04s/it, loss=0.886, v_num=9623]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████| 2715/2715 [47:15<00:00,  1.04s/it, loss=0.886, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 43152: 'val_iou_loss' reached 0.24330 (best 0.24330), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=15-step=43152.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  99%|██████████████████████████████████▊| 2697/2715 [47:15<00:18,  1.05s/it, loss=0.907, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  99%|██████████████████████████████████▊| 2698/2715 [47:19<00:17,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16:  99%|██████████████████████████████████▊| 2699/2715 [47:20<00:16,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16:  99%|██████████████████████████████████▊| 2700/2715 [47:21<00:15,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16:  99%|██████████████████████████████████▊| 2701/2715 [47:22<00:14,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▊| 2702/2715 [47:23<00:13,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▊| 2703/2715 [47:24<00:12,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▊| 2704/2715 [47:25<00:11,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▊| 2705/2715 [47:26<00:10,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2706/2715 [47:27<00:09,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2707/2715 [47:28<00:08,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2708/2715 [47:29<00:07,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2709/2715 [47:30<00:06,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2710/2715 [47:32<00:05,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2711/2715 [47:33<00:04,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2712/2715 [47:34<00:03,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2713/2715 [47:35<00:02,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2714/2715 [47:36<00:01,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|███████████████████████████████████| 2715/2715 [47:37<00:00,  1.05s/it, loss=0.907, v_num=9623]\u001b[A\n",
      "Epoch 16: 100%|███████████████████████████████████| 2715/2715 [47:37<00:00,  1.05s/it, loss=0.907, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 45849: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  99%|██████████████████████████████████▊| 2697/2715 [47:03<00:18,  1.05s/it, loss=0.867, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  99%|██████████████████████████████████▊| 2698/2715 [47:07<00:17,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17:  99%|██████████████████████████████████▊| 2699/2715 [47:08<00:16,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17:  99%|██████████████████████████████████▊| 2700/2715 [47:09<00:15,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17:  99%|██████████████████████████████████▊| 2701/2715 [47:10<00:14,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▊| 2702/2715 [47:11<00:13,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▊| 2703/2715 [47:12<00:12,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▊| 2704/2715 [47:13<00:11,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▊| 2705/2715 [47:15<00:10,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2706/2715 [47:16<00:09,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2707/2715 [47:17<00:08,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2708/2715 [47:18<00:07,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2709/2715 [47:19<00:06,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2710/2715 [47:20<00:05,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2711/2715 [47:21<00:04,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2712/2715 [47:22<00:03,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2713/2715 [47:23<00:02,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2714/2715 [47:24<00:01,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|███████████████████████████████████| 2715/2715 [47:25<00:00,  1.05s/it, loss=0.867, v_num=9623]\u001b[A\n",
      "Epoch 17: 100%|███████████████████████████████████| 2715/2715 [47:25<00:00,  1.05s/it, loss=0.867, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 48546: 'val_iou_loss' reached 0.24216 (best 0.24216), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=17-step=48546.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  99%|██████████████████████████████████▊| 2697/2715 [46:57<00:18,  1.04s/it, loss=0.927, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  99%|██████████████████████████████████▊| 2698/2715 [47:01<00:17,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18:  99%|██████████████████████████████████▊| 2699/2715 [47:02<00:16,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18:  99%|██████████████████████████████████▊| 2700/2715 [47:03<00:15,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18:  99%|██████████████████████████████████▊| 2701/2715 [47:04<00:14,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▊| 2702/2715 [47:05<00:13,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▊| 2703/2715 [47:06<00:12,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▊| 2704/2715 [47:07<00:11,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▊| 2705/2715 [47:08<00:10,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2706/2715 [47:09<00:09,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2707/2715 [47:11<00:08,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2708/2715 [47:12<00:07,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2709/2715 [47:13<00:06,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2710/2715 [47:14<00:05,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2711/2715 [47:15<00:04,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2712/2715 [47:16<00:03,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2713/2715 [47:17<00:02,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2714/2715 [47:18<00:01,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|███████████████████████████████████| 2715/2715 [47:19<00:00,  1.05s/it, loss=0.927, v_num=9623]\u001b[A\n",
      "Epoch 18: 100%|███████████████████████████████████| 2715/2715 [47:19<00:00,  1.05s/it, loss=0.927, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 51243: 'val_iou_loss' reached 0.24097 (best 0.24097), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=18-step=51243.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  99%|██████████████████████████████████▊| 2697/2715 [46:19<00:18,  1.03s/it, loss=0.844, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  99%|██████████████████████████████████▊| 2698/2715 [46:22<00:17,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19:  99%|██████████████████████████████████▊| 2699/2715 [46:23<00:16,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19:  99%|██████████████████████████████████▊| 2700/2715 [46:25<00:15,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19:  99%|██████████████████████████████████▊| 2701/2715 [46:26<00:14,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▊| 2702/2715 [46:27<00:13,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▊| 2703/2715 [46:28<00:12,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▊| 2704/2715 [46:29<00:11,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▊| 2705/2715 [46:30<00:10,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2706/2715 [46:31<00:09,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2707/2715 [46:32<00:08,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2708/2715 [46:33<00:07,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2709/2715 [46:34<00:06,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2710/2715 [46:35<00:05,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2711/2715 [46:37<00:04,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2712/2715 [46:38<00:03,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2713/2715 [46:39<00:02,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2714/2715 [46:40<00:01,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|███████████████████████████████████| 2715/2715 [46:41<00:00,  1.03s/it, loss=0.844, v_num=9623]\u001b[A\n",
      "Epoch 19: 100%|███████████████████████████████████| 2715/2715 [46:41<00:00,  1.03s/it, loss=0.844, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 53940: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  99%|██████████████████████████████████▊| 2697/2715 [46:35<00:18,  1.04s/it, loss=0.885, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  99%|██████████████████████████████████▊| 2698/2715 [46:39<00:17,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20:  99%|██████████████████████████████████▊| 2699/2715 [46:40<00:16,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20:  99%|██████████████████████████████████▊| 2700/2715 [46:41<00:15,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20:  99%|██████████████████████████████████▊| 2701/2715 [46:43<00:14,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▊| 2702/2715 [46:44<00:13,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▊| 2703/2715 [46:45<00:12,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▊| 2704/2715 [46:46<00:11,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▊| 2705/2715 [46:47<00:10,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▉| 2706/2715 [46:48<00:09,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▉| 2707/2715 [46:49<00:08,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▉| 2708/2715 [46:50<00:07,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▉| 2709/2715 [46:51<00:06,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▉| 2710/2715 [46:53<00:05,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▉| 2711/2715 [46:54<00:04,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▉| 2712/2715 [46:55<00:03,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▉| 2713/2715 [46:56<00:02,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████▉| 2714/2715 [46:57<00:01,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|███████████████████████████████████| 2715/2715 [46:58<00:00,  1.04s/it, loss=0.885, v_num=9623]\u001b[A\n",
      "Epoch 20: 100%|███████████████████████████████████| 2715/2715 [46:58<00:00,  1.04s/it, loss=0.885, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 56637: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  99%|██████████████████████████████████▊| 2697/2715 [46:14<00:18,  1.03s/it, loss=0.912, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  99%|██████████████████████████████████▊| 2698/2715 [46:19<00:17,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21:  99%|██████████████████████████████████▊| 2699/2715 [46:20<00:16,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21:  99%|██████████████████████████████████▊| 2700/2715 [46:21<00:15,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21:  99%|██████████████████████████████████▊| 2701/2715 [46:23<00:14,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▊| 2702/2715 [46:24<00:13,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▊| 2703/2715 [46:25<00:12,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▊| 2704/2715 [46:26<00:11,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▊| 2705/2715 [46:27<00:10,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▉| 2706/2715 [46:28<00:09,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▉| 2707/2715 [46:29<00:08,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▉| 2708/2715 [46:30<00:07,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▉| 2709/2715 [46:31<00:06,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▉| 2710/2715 [46:32<00:05,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▉| 2711/2715 [46:34<00:04,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▉| 2712/2715 [46:35<00:03,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▉| 2713/2715 [46:36<00:02,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████▉| 2714/2715 [46:37<00:01,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|███████████████████████████████████| 2715/2715 [46:38<00:00,  1.03s/it, loss=0.912, v_num=9623]\u001b[A\n",
      "Epoch 21: 100%|███████████████████████████████████| 2715/2715 [46:38<00:00,  1.03s/it, loss=0.912, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 59334: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00022: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Epoch 22:  99%|██████████████████████████████████▊| 2697/2715 [45:48<00:18,  1.02s/it, loss=0.925, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  99%|██████████████████████████████████▊| 2698/2715 [45:53<00:17,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22:  99%|██████████████████████████████████▊| 2699/2715 [45:54<00:16,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22:  99%|██████████████████████████████████▊| 2700/2715 [45:55<00:15,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22:  99%|██████████████████████████████████▊| 2701/2715 [45:57<00:14,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▊| 2702/2715 [45:58<00:13,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▊| 2703/2715 [45:59<00:12,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▊| 2704/2715 [46:00<00:11,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▊| 2705/2715 [46:01<00:10,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▉| 2706/2715 [46:02<00:09,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▉| 2707/2715 [46:03<00:08,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▉| 2708/2715 [46:04<00:07,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▉| 2709/2715 [46:05<00:06,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▉| 2710/2715 [46:07<00:05,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▉| 2711/2715 [46:08<00:04,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▉| 2712/2715 [46:09<00:03,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▉| 2713/2715 [46:10<00:02,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████▉| 2714/2715 [46:11<00:01,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|███████████████████████████████████| 2715/2715 [46:12<00:00,  1.02s/it, loss=0.925, v_num=9623]\u001b[A\n",
      "Epoch 22: 100%|███████████████████████████████████| 2715/2715 [46:12<00:00,  1.02s/it, loss=0.925, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 62031: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  99%|████████████████████████████████████▊| 2697/2715 [45:59<00:18,  1.02s/it, loss=0.9, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  99%|████████████████████████████████████▊| 2698/2715 [46:04<00:17,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23:  99%|████████████████████████████████████▊| 2699/2715 [46:05<00:16,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23:  99%|████████████████████████████████████▊| 2700/2715 [46:06<00:15,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23:  99%|████████████████████████████████████▊| 2701/2715 [46:08<00:14,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▊| 2702/2715 [46:09<00:13,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▊| 2703/2715 [46:10<00:12,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▊| 2704/2715 [46:11<00:11,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▊| 2705/2715 [46:12<00:10,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▉| 2706/2715 [46:13<00:09,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▉| 2707/2715 [46:14<00:08,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▉| 2708/2715 [46:15<00:07,  1.02s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▉| 2709/2715 [46:16<00:06,  1.03s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▉| 2710/2715 [46:17<00:05,  1.03s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▉| 2711/2715 [46:18<00:04,  1.03s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▉| 2712/2715 [46:20<00:03,  1.03s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▉| 2713/2715 [46:21<00:02,  1.03s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|████████████████████████████████████▉| 2714/2715 [46:22<00:01,  1.03s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|█████████████████████████████████████| 2715/2715 [46:23<00:00,  1.03s/it, loss=0.9, v_num=9623]\u001b[A\n",
      "Epoch 23: 100%|█████████████████████████████████████| 2715/2715 [46:23<00:00,  1.03s/it, loss=0.9, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 64728: 'val_iou_loss' reached 0.24026 (best 0.24026), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=23-step=64728.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  99%|██████████████████████████████████▊| 2697/2715 [45:58<00:18,  1.02s/it, loss=0.879, v_num=9623]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  99%|██████████████████████████████████▊| 2698/2715 [46:02<00:17,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24:  99%|██████████████████████████████████▊| 2699/2715 [46:03<00:16,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24:  99%|██████████████████████████████████▊| 2700/2715 [46:04<00:15,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24:  99%|██████████████████████████████████▊| 2701/2715 [46:05<00:14,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▊| 2702/2715 [46:07<00:13,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▊| 2703/2715 [46:08<00:12,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▊| 2704/2715 [46:09<00:11,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▊| 2705/2715 [46:10<00:10,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▉| 2706/2715 [46:11<00:09,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▉| 2707/2715 [46:12<00:08,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▉| 2708/2715 [46:13<00:07,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▉| 2709/2715 [46:14<00:06,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▉| 2710/2715 [46:15<00:05,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▉| 2711/2715 [46:16<00:04,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▉| 2712/2715 [46:17<00:03,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▉| 2713/2715 [46:19<00:02,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████▉| 2714/2715 [46:20<00:01,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|███████████████████████████████████| 2715/2715 [46:21<00:00,  1.02s/it, loss=0.879, v_num=9623]\u001b[A\n",
      "Epoch 24: 100%|███████████████████████████████████| 2715/2715 [46:21<00:00,  1.02s/it, loss=0.879, v_num=9623]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 67425: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  74%|█████████████████████████▉         | 2013/2715 [31:41<11:03,  1.06it/s, loss=0.877, v_num=9623]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_train[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3eb6095c-4b3f-47db-8920-92242e50f36b",
   "metadata": {},
   "source": [
    "n_images=10\n",
    "fig, axs = plt.subplots(4, n_images, figsize=(18,14),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.max_tile_size = config.model_params.hyperparameters.max_tile_size\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "# import torch\n",
    "import numpy as np\n",
    "from ml4floods.models.utils import metrics\n",
    "from ml4floods.models.model_setup import get_model_inference_function\n",
    "import pandas as pd\n",
    "\n",
    "# model.to(\"cuda\")\n",
    "inference_function = get_model_inference_function(model, config, apply_normalization=False, activation=\"softmax\")\n",
    "\n",
    "# dataset2 = get_dataset(config.data_params)\n",
    "dl = dataset.val_dataloader() # pytorch Dataloader\n",
    "print(str(dl.batch_size))\n",
    "\n",
    "# Otherwise fails when reading test dataset from remote bucket\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "thresholds_water = [0,1e-3,1e-2]+np.arange(0.5,.96,.05).tolist() + [.99,.995,.999]\n",
    "\n",
    "mets = metrics.compute_metrics(\n",
    "    dl,\n",
    "    inference_function, \n",
    "    thresholds_water=thresholds_water, \n",
    "    plot=False, convert_targets=False)\n",
    "\n",
    "label_names = [\"land\", \"water\", \"cloud\"]\n",
    "metrics.plot_metrics(mets, label_names)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9f8d76e-a1fc-456e-b3f9-8e53d0da13a0",
   "metadata": {},
   "source": [
    "train_fc_loss = model.train_fc_loss\n",
    "train_iou_loss = model.train_iou_loss\n",
    "train_compound_loss = model.train_compound_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(dl.dataset, \"image_files\"):\n",
    "    cems_code = [os.path.basename(f).split(\"_\")[0] for f in dl.dataset.image_files]\n",
    "else:\n",
    "    cems_code = [os.path.basename(f.file_name).split(\"_\")[0] for f in dl.dataset.list_of_windows]\n",
    "\n",
    "iou_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_iou,\n",
    "                                                    label_names=[f\"IoU_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "recall_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_recall,\n",
    "                                                       label_names=[f\"Recall_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "join_data_per_code = pd.merge(recall_per_code,iou_per_code,on=\"code\")\n",
    "join_data_per_code = join_data_per_code.set_index(\"code\")\n",
    "join_data_per_code = join_data_per_code*100\n",
    "print(f\"Mean values across flood events: {join_data_per_code.mean(axis=0).to_dict()}\")\n",
    "join_data_per_code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6233dfa4-7736-4f55-a3a1-ca90f6bd8944",
   "metadata": {},
   "source": [
    "# import torch\n",
    "from pytorch_lightning.utilities.cloud_io import atomic_save\n",
    "from ml4floods.models.config_setup import save_json\n",
    "\n",
    "# Save in the cloud and in the wandb logger save dir\n",
    "atomic_save(model.state_dict(), f\"{experiment_path}/model_irirnir_worldflood_model_1_epoch_2_gamma_5_alpha_0_001.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config_model_irirnir_worldflood_model_1_epoch_2_gamma_5_alpha_0_001.pt.json\"\n",
    "save_json(config, config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b6829-07cf-4831-b114-20230d3b3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f\"{experiment_path}/model_irirnir_worldflood_model_1_epoch_2_adaptive_gamma_alpha_0_001.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config_irirnir_worldflood_model_1_epoch_2_adaptive_gamma_alpha_0_001.json\"\n",
    "import json\n",
    "with open(config_file_path, 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wandb_logger)\n",
    "if setup_weights_and_biases:\n",
    "    torch.save(model.state_dict(), os.path.join(wandb_logger.save_dir, 'model_irirnir_worldflood_model_1_epoch_2_adaptive_gamma_alpha_0_001.pt'))\n",
    "    wandb.save(os.path.join(wandb_logger.save_dir, 'model_irirnir_worldflood_model_1_epoch_2_adaptive_gamma_alpha_0_001.pt')) # Copy weights to weights and biases server\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f5845-b502-41df-afdb-df2af60b5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_val[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbafaab-0986-4de8-98ef-0bfb21c439d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image_start=7\n",
    "n_images=14\n",
    "count=int(n_images-n_image_start)\n",
    "fig, axs = plt.subplots(4, count, figsize=(18,14),tight_layout=True)\n",
    "importlib.reload(flooding_model)\n",
    "flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"bgri\",axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"bgri\",bands_show=[\"B8\",\"B8\", \"B8\"],axs=axs[1],max_clip_val=3500.)\n",
    "# flooding_model.plot_batch(batch_val[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_val[\"mask\"][n_image_start:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[n_image_start:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f0f77-f767-42bd-95d3-7436e91cf27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (pt-gpu)",
   "language": "python",
   "name": "pt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
