{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "early-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viplab/pt-gpu/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-history",
   "metadata": {},
   "source": [
    "## Load flooding configuration file from local device or gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "toxic-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Config for experiment:  worldfloods_demo_test\n",
      "{   'data_params': {   'batch_size': 32,\n",
      "                       'bucket_id': 'ml4cc_data_lake',\n",
      "                       'channel_configuration': 'all',\n",
      "                       'download': {'test': True, 'train': True, 'val': True},\n",
      "                       'filter_windows': {   'apply': False,\n",
      "                                             'threshold_clouds': 0.5,\n",
      "                                             'version': 'v1'},\n",
      "                       'input_folder': 'S2',\n",
      "                       'loader_type': 'local',\n",
      "                       'num_workers': 4,\n",
      "                       'path_to_splits': 'worldfloods',\n",
      "                       'target_folder': 'gt',\n",
      "                       'test_transformation': {'normalize': True},\n",
      "                       'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
      "                       'train_transformation': {'normalize': True},\n",
      "                       'window_size': [256, 256]},\n",
      "    'experiment_name': 'worldfloods_demo_test',\n",
      "    'gpus': '0',\n",
      "    'model_params': {   'hyperparameters': {   'channel_configuration': 'all',\n",
      "                                               'early_stopping_patience': 4,\n",
      "                                               'label_names': [   'land',\n",
      "                                                                  'water',\n",
      "                                                                  'cloud'],\n",
      "                                               'lr': 0.0001,\n",
      "                                               'lr_decay': 0.5,\n",
      "                                               'lr_patience': 2,\n",
      "                                               'max_epochs': 10,\n",
      "                                               'max_tile_size': 256,\n",
      "                                               'metric_monitor': 'val_dice_loss',\n",
      "                                               'model_type': 'linear',\n",
      "                                               'num_channels': 13,\n",
      "                                               'num_classes': 3,\n",
      "                                               'val_every': 1,\n",
      "                                               'weight_per_class': [   1.93445299,\n",
      "                                                                       36.60054169,\n",
      "                                                                       2.19400729]},\n",
      "                        'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
      "                        'model_version': 'v1',\n",
      "                        'test': True,\n",
      "                        'train': True},\n",
      "    'resume_from_checkpoint': False,\n",
      "    'seed': 12}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 'worldfloods_demo_test',\n",
       " 'seed': 12,\n",
       " 'model_params': {'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       "  'model_version': 'v1',\n",
       "  'hyperparameters': {'max_tile_size': 256,\n",
       "   'metric_monitor': 'val_dice_loss',\n",
       "   'channel_configuration': 'all',\n",
       "   'label_names': ['land', 'water', 'cloud'],\n",
       "   'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "   'model_type': 'linear',\n",
       "   'num_classes': 3,\n",
       "   'max_epochs': 10,\n",
       "   'val_every': 1,\n",
       "   'lr': 0.0001,\n",
       "   'lr_decay': 0.5,\n",
       "   'lr_patience': 2,\n",
       "   'early_stopping_patience': 4,\n",
       "   'num_channels': 13},\n",
       "  'train': True,\n",
       "  'test': True},\n",
       " 'data_params': {'loader_type': 'local',\n",
       "  'num_workers': 4,\n",
       "  'filter_windows': {'version': 'v1', 'threshold_clouds': 0.5, 'apply': False},\n",
       "  'download': {'train': True, 'val': True, 'test': True},\n",
       "  'bucket_id': 'ml4cc_data_lake',\n",
       "  'path_to_splits': 'worldfloods',\n",
       "  'train_test_split_file': '2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json',\n",
       "  'input_folder': 'S2',\n",
       "  'target_folder': 'gt',\n",
       "  'batch_size': 32,\n",
       "  'window_size': [256, 256],\n",
       "  'channel_configuration': 'all',\n",
       "  'train_transformation': {'normalize': True},\n",
       "  'test_transformation': {'normalize': True}},\n",
       " 'resume_from_checkpoint': False,\n",
       " 'gpus': '0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "import pkg_resources\n",
    "\n",
    "# Set filepath to configuration files\n",
    "# config_fp = 'path/to/worldfloods_template.json'\n",
    "config_fp = pkg_resources.resource_filename(\"ml4floods\",\"models/configurations/worldfloods_template.json\")\n",
    "\n",
    "config = get_default_config(config_fp)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-scope",
   "metadata": {},
   "source": [
    "## Step 2: Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-edgar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'bgri',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 4},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.experiment_name = 'training_flooding_bgri'\n",
    "config.data_params.channel_configuration = 'bgri'\n",
    "config.model_params.hyperparameters.channel_configuration = 'bgri'\n",
    "config.model_params.hyperparameters.num_channels = 4\n",
    "config.data_params.bucket_id = \"\"\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scientific-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 194151  tiles\n",
      "val 1284  tiles\n",
      "test 11  tiles\n",
      "CPU times: user 1.42 s, sys: 1.48 s, total: 2.9 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from ml4floods.models.dataset_setup import get_dataset\n",
    "\n",
    "config.data_params.batch_size = 96 # control this depending on the space on your GPU!\n",
    "config.data_params.loader_type = 'local'\n",
    "config.data_params.path_to_splits = \"/mnt/d/Flooding/worldfloods_v1_0\" # local folder to download the data\n",
    "config.data_params.train_test_split_file = \"/mnt/d/Flooding/train_test_split_local.json\"\n",
    "\n",
    "config.data_params[\"download\"] = {\"train\": True, \"val\": True, \"test\": True} # download only test data\n",
    "# config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json\" # use this to train with all the data\n",
    "config.data_params.num_workers = 24\n",
    "\n",
    "# If files are not in config.data_params.path_to_splits this will trigger the download of the products.\n",
    "dataset = get_dataset(config.data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-harassment",
   "metadata": {},
   "source": [
    "## Verfify data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-driver",
   "metadata": {},
   "source": [
    "#### Verify training data\n",
    "Data format here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fallen-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n"
     ]
    }
   ],
   "source": [
    "train_dl = dataset.train_dataloader()\n",
    "train_dl_iter = iter(train_dl)\n",
    "print(len(train_dl_iter))\n",
    "batch_train = next(train_dl_iter)\n",
    "\n",
    "# batch_train[\"image\"].shape, batch_train[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-spanking",
   "metadata": {},
   "source": [
    "Verify validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "injured-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "val_dl = dataset.val_dataloader()\n",
    "\n",
    "val_dl_iter = iter(val_dl)\n",
    "print(len(val_dl_iter))\n",
    "batch_val = next(val_dl_iter)\n",
    "\n",
    "# batch_val[\"image\"].shape, batch_val[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "significant-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "test_dl = dataset.test_dataloader()\n",
    "\n",
    "test_dl_iter = iter(test_dl)\n",
    "print(len(test_dl_iter))\n",
    "\n",
    "batch_test = next(test_dl_iter)\n",
    "# batch_test[\"image\"].shape, batch_test[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-electron",
   "metadata": {},
   "source": [
    "### Plot batch by using ml4flood model \n",
    "check detail here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31b26d6b-ecc5-4648-92f5-299b6099f321",
   "metadata": {},
   "source": [
    "from models import flooding_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flooding_model.plot_batch(batch_train[\"image\"])\n",
    "\n",
    "n_images=6\n",
    "fig, axs = plt.subplots(3,n_images, figsize=(18,10),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7279717-cfb1-4d20-a915-869d1ab3ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from models import flooding_model\n",
    "flooding_model = importlib.reload(flooding_model)\n",
    "\n",
    "# batch_train_rgb = flooding_model.batch_to_unnorm_rgb(batch_train[\"image\"])\n",
    "# # batch_train_rgb.shape\n",
    "# plt.imshow(batch_train_rgb[2])\n",
    "# plt.show()\n",
    "\n",
    "# batch_train_rgb_mask = flooding_model.batch_mask_to_rgb(batch_train[\"mask\"])\n",
    "# plt.imshow(batch_train_rgb_mask[2])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-cleanup",
   "metadata": {},
   "source": [
    "## Step 3: Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proud-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_folder': 'gs://ml4cc_data_lake/0_DEV/2_Mart/2_MLModelMart',\n",
       " 'model_version': 'v1',\n",
       " 'hyperparameters': {'max_tile_size': 256,\n",
       "  'metric_monitor': 'val_dice_loss',\n",
       "  'channel_configuration': 'bgri',\n",
       "  'label_names': ['land', 'water', 'cloud'],\n",
       "  'weight_per_class': [1.93445299, 36.60054169, 2.19400729],\n",
       "  'model_type': 'linear',\n",
       "  'num_classes': 3,\n",
       "  'max_epochs': 10,\n",
       "  'val_every': 1,\n",
       "  'lr': 0.0001,\n",
       "  'lr_decay': 0.5,\n",
       "  'lr_patience': 2,\n",
       "  'early_stopping_patience': 4,\n",
       "  'num_channels': 4},\n",
       " 'train': True,\n",
       " 'test': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # folder to store the trained model (it will create a subfolder with the name of the experiment)\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colonial-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.model_folder = \"train_models\" \n",
    "os.makedirs(\"train_models\", exist_ok=True)\n",
    "config.model_params.test = False\n",
    "config.model_params.train = True\n",
    "config.model_params.hyperparameters.model_type = \"unet_simple\" # Currently implemented: simplecnn, unet, linear, unet_simple\n",
    "config.model_params.hyperparameters.metric_monitor = 'val_iou_loss' #IoU Loss\n",
    "# config.model_params.hyperparameters.num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternative-bonus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleUNet(\n",
       "  (dconv_down1): Sequential(\n",
       "    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dconv_up3): Sequential(\n",
       "    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up2): Sequential(\n",
       "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up1): Sequential(\n",
       "    (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from models.flooding_model import WorldFloodsModel, DistilledTrainingModel, WorldFloodsModel2, WorldFloodsModel1\n",
    "importlib.reload(flooding_model)\n",
    "simple_model_params = copy.deepcopy(config.model_params)\n",
    "# simple_model_params['hyperparameters']['model_type']=\"unet_simple\"\n",
    "\n",
    "# model = DistilledTrainingModel(config.model_params, simple_model_params)\n",
    "model = WorldFloodsModel2(config.model_params) # Focal loss and IoU loss\n",
    "# model = WorldFloodsModel1(config.model_params) # Focal loss and Dice loss\n",
    "net = model.network\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c4307a4-d88a-417c-94aa-4dd145299a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module SimpleUNet is treated as a zero-op.\n",
      "SimpleUNet(\n",
      "  1.95 M, 100.000% Params, 10.69 GMac, 100.000% MACs, \n",
      "  (dconv_down1): Sequential(\n",
      "    10.43 k, 0.536% Params, 687.87 MMac, 6.437% MACs, \n",
      "    (0): Conv2d(1.18 k, 0.061% Params, 77.59 MMac, 0.726% MACs, 4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 2.1 MMac, 0.020% MACs, inplace=True)\n",
      "    (2): Conv2d(9.25 k, 0.475% Params, 606.08 MMac, 5.672% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 2.1 MMac, 0.020% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down2): Sequential(\n",
      "    55.42 k, 2.846% Params, 910.16 MMac, 8.518% MACs, \n",
      "    (0): Conv2d(18.5 k, 0.950% Params, 303.04 MMac, 2.836% MACs, 32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 1.05 MMac, 0.010% MACs, inplace=True)\n",
      "    (2): Conv2d(36.93 k, 1.896% Params, 605.03 MMac, 5.662% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 1.05 MMac, 0.010% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down3): Sequential(\n",
      "    221.44 k, 11.372% Params, 908.07 MMac, 8.498% MACs, \n",
      "    (0): Conv2d(73.86 k, 3.793% Params, 302.51 MMac, 2.831% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 524.29 KMac, 0.005% MACs, inplace=True)\n",
      "    (2): Conv2d(147.58 k, 7.579% Params, 604.5 MMac, 5.657% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 524.29 KMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_down4): Sequential(\n",
      "    885.25 k, 45.462% Params, 907.02 MMac, 8.488% MACs, \n",
      "    (0): Conv2d(295.17 k, 15.158% Params, 302.25 MMac, 2.829% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 262.14 KMac, 0.002% MACs, inplace=True)\n",
      "    (2): Conv2d(590.08 k, 30.303% Params, 604.24 MMac, 5.655% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 262.14 KMac, 0.002% MACs, inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(0, 0.000% Params, 3.67 MMac, 0.034% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dconv_up3): Sequential(\n",
      "    590.08 k, 30.303% Params, 2.42 GMac, 22.629% MACs, \n",
      "    (0): Conv2d(442.5 k, 22.724% Params, 1.81 GMac, 16.962% MACs, 384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 524.29 KMac, 0.005% MACs, inplace=True)\n",
      "    (2): Conv2d(147.58 k, 7.579% Params, 604.5 MMac, 5.657% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 524.29 KMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_up2): Sequential(\n",
      "    147.58 k, 7.579% Params, 2.42 GMac, 22.648% MACs, \n",
      "    (0): Conv2d(110.66 k, 5.683% Params, 1.81 GMac, 16.966% MACs, 192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 1.05 MMac, 0.010% MACs, inplace=True)\n",
      "    (2): Conv2d(36.93 k, 1.896% Params, 605.03 MMac, 5.662% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 1.05 MMac, 0.010% MACs, inplace=True)\n",
      "  )\n",
      "  (dconv_up1): Sequential(\n",
      "    36.93 k, 1.896% Params, 2.42 GMac, 22.687% MACs, \n",
      "    (0): Conv2d(27.68 k, 1.422% Params, 1.81 GMac, 16.976% MACs, 96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.000% Params, 2.1 MMac, 0.020% MACs, inplace=True)\n",
      "    (2): Conv2d(9.25 k, 0.475% Params, 606.08 MMac, 5.672% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.000% Params, 2.1 MMac, 0.020% MACs, inplace=True)\n",
      "  )\n",
      "  (conv_last): Conv2d(99, 0.005% Params, 6.49 MMac, 0.061% MACs, 32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Computational complexity:       10.69 GMac\n",
      "Number of parameters:           1.95 M  \n"
     ]
    }
   ],
   "source": [
    "# Compuatation complexity of network\n",
    "from ptflops import get_model_complexity_info\n",
    "macs, params = get_model_complexity_info(net, (config.model_params.hyperparameters.num_channels, config.model_params.hyperparameters.max_tile_size, config.model_params.hyperparameters.max_tile_size), as_strings=True, print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seventh-stationery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrongan93\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/viplab/VipLabProjects/satellite-knowledge-distillation/wandb/run-20221006_025253-1wuuca2u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/trongan93/satellite-knowledge-distillation/runs/1wuuca2u\" target=\"_blank\">fluent-night-56</a></strong> to <a href=\"https://wandb.ai/trongan93/satellite-knowledge-distillation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viplab/pt-gpu/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "setup_weights_and_biases = True\n",
    "if setup_weights_and_biases:\n",
    "    import wandb\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "    # UNCOMMENT ON FIRST RUN TO LOGIN TO Weights and Biases (only needs to be done once)\n",
    "    wandb.login()\n",
    "    run = wandb.init()\n",
    "\n",
    "    # Specifies who is logging the experiment to wandb\n",
    "    config['wandb_entity'] = 'ml4floods'\n",
    "    # Specifies which wandb project to log to, multiple runs can exist in the same project\n",
    "    config['wandb_project'] = 'worldfloods-trongan-test'\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        name=config.experiment_name,\n",
    "        project=config.wandb_project, \n",
    "        entity=config.wandb_entity\n",
    "    )\n",
    "else:\n",
    "    wandb_logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "downtown-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained model will be stored in train_models/training_flooding_bgri\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "experiment_path = f\"{config.model_params.model_folder}/{config.experiment_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{experiment_path}/checkpoint\",\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_iou_loss',\n",
    "    mode='min',\n",
    "#     prefix=''\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_iou_loss',\n",
    "    patience=10,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "# monitor='val_iou_loss'\n",
    "# monitor='val_dice_loss'\n",
    "\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "print(f\"The trained model will be stored in {config.model_params.model_folder}/{config.experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "searching-charity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config.gpus = 2 # which gpu to use \n",
    "# config.gpus = None # to not use GPU\n",
    "config.model_params.hyperparameters.max_epochs = 100 # train for maximum 4 epochs\n",
    "\n",
    "trainer = Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    auto_lr_find=False,\n",
    "    benchmark=False,\n",
    "    max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "    check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "    strategy='dp',\n",
    "    accelerator='gpu',\n",
    "    devices=config.gpus\n",
    "    # resume_from_checkpoint='~/Projects/github/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=0-step=24269.ckpt'\n",
    ")\n",
    "# config\n",
    "# https://wandb.ai/wandb/wandb-lightning/reports/Multi-GPU-Training-Using-PyTorch-Lightning--VmlldzozMTk3NTk\n",
    "# resume_from_checkpoint='/home/eeaiserver/viplab_projects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=39-step=161799.ckpt'\n",
    "# resume_from_checkpoint='~/Projects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=30-step=47026.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-india",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | network | SimpleUNet | 1.9 M \n",
      "---------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.789     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viplab/pt-gpu/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|████████████████████████████████████▋| 2023/2037 [14:39<00:06,  2.30it/s, loss=1.07, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 2024/2037 [14:43<00:05,  2.29it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 2025/2037 [14:44<00:05,  2.29it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████████████████▊| 2026/2037 [14:46<00:04,  2.29it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 2027/2037 [14:47<00:04,  2.28it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 2028/2037 [14:48<00:03,  2.28it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 2029/2037 [14:50<00:03,  2.28it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▊| 2030/2037 [14:51<00:03,  2.28it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 2031/2037 [14:52<00:02,  2.28it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 2032/2037 [14:53<00:02,  2.27it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 2033/2037 [14:55<00:01,  2.27it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 2034/2037 [14:56<00:01,  2.27it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 2035/2037 [14:57<00:00,  2.27it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████▉| 2036/2037 [14:58<00:00,  2.27it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|█████████████████████████████████████| 2037/2037 [14:58<00:00,  2.27it/s, loss=1.07, v_num=ca2u]\u001b[A\n",
      "Epoch 0: 100%|█████████████████████████████████████| 2037/2037 [14:58<00:00,  2.27it/s, loss=1.07, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 2023: 'val_iou_loss' reached 0.37734 (best 0.37734), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=0-step=2023.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▍                                      | 23/2037 [00:16<24:24,  1.38it/s, loss=1.07, v_num=ca2u]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/viplab/pt-gpu/lib/python3.10/site-packages/wandb/vendor/watchdog/observers/api.py\", line 199, in run\n",
      "    self.dispatch_events(self.event_queue, self.timeout)\n",
      "  File \"/home/viplab/pt-gpu/lib/python3.10/site-packages/wandb/vendor/watchdog/observers/api.py\", line 368, in dispatch_events\n",
      "    handler.dispatch(event)\n",
      "  File \"/home/viplab/pt-gpu/lib/python3.10/site-packages/wandb/vendor/watchdog/events.py\", line 454, in dispatch\n",
      "    _method_map[event_type](event)\n",
      "  File \"/home/viplab/pt-gpu/lib/python3.10/site-packages/wandb/filesync/dir_watcher.py\", line 309, in _on_file_moved\n",
      "    del self._file_event_handlers[old_save_name]\n",
      "KeyError: 'media/images/train_overlay_65_13c0915d226521fb56bb.png'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99%|████████████████████████████████████▋| 2023/2037 [19:14<00:07,  1.75it/s, loss=1.01, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  99%|████████████████████████████████████▊| 2024/2037 [19:19<00:07,  1.75it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1:  99%|████████████████████████████████████▊| 2025/2037 [19:20<00:06,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1:  99%|████████████████████████████████████▊| 2026/2037 [19:21<00:06,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▊| 2027/2037 [19:23<00:05,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▊| 2028/2037 [19:24<00:05,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▊| 2029/2037 [19:25<00:04,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▊| 2030/2037 [19:26<00:04,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2031/2037 [19:28<00:03,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2032/2037 [19:29<00:02,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2033/2037 [19:30<00:02,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2034/2037 [19:31<00:01,  1.74it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2035/2037 [19:33<00:01,  1.73it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████▉| 2036/2037 [19:34<00:00,  1.73it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████████████████████| 2037/2037 [19:34<00:00,  1.73it/s, loss=1.01, v_num=ca2u]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████████████████████| 2037/2037 [19:34<00:00,  1.73it/s, loss=1.01, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 4046: 'val_iou_loss' reached 0.37713 (best 0.37713), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=1-step=4046.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  99%|████████████████████████████████████▋| 2023/2037 [19:16<00:08,  1.75it/s, loss=0.95, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  99%|████████████████████████████████████▊| 2024/2037 [19:21<00:07,  1.74it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2:  99%|████████████████████████████████████▊| 2025/2037 [19:22<00:06,  1.74it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2:  99%|████████████████████████████████████▊| 2026/2037 [19:23<00:06,  1.74it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▊| 2027/2037 [19:25<00:05,  1.74it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▊| 2028/2037 [19:26<00:05,  1.74it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▊| 2029/2037 [19:27<00:04,  1.74it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▊| 2030/2037 [19:29<00:04,  1.74it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2031/2037 [19:30<00:03,  1.73it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2032/2037 [19:31<00:02,  1.73it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2033/2037 [19:33<00:02,  1.73it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2034/2037 [19:34<00:01,  1.73it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2035/2037 [19:35<00:01,  1.73it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████▉| 2036/2037 [19:37<00:00,  1.73it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|█████████████████████████████████████| 2037/2037 [19:37<00:00,  1.73it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 2: 100%|█████████████████████████████████████| 2037/2037 [19:37<00:00,  1.73it/s, loss=0.95, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 6069: 'val_iou_loss' reached 0.27842 (best 0.27842), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=2-step=6069.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  99%|███████████████████████████████████▊| 2023/2037 [19:25<00:08,  1.74it/s, loss=0.961, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████████▊| 2024/2037 [19:29<00:07,  1.73it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████████▊| 2025/2037 [19:30<00:06,  1.73it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████████▊| 2026/2037 [19:32<00:06,  1.73it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▊| 2027/2037 [19:33<00:05,  1.73it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▊| 2028/2037 [19:34<00:05,  1.73it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▊| 2029/2037 [19:35<00:04,  1.73it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▉| 2030/2037 [19:37<00:04,  1.72it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▉| 2031/2037 [19:38<00:03,  1.72it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▉| 2032/2037 [19:39<00:02,  1.72it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▉| 2033/2037 [19:41<00:02,  1.72it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▉| 2034/2037 [19:42<00:01,  1.72it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▉| 2035/2037 [19:43<00:01,  1.72it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████▉| 2036/2037 [19:44<00:00,  1.72it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|████████████████████████████████████| 2037/2037 [19:45<00:00,  1.72it/s, loss=0.961, v_num=ca2u]\u001b[A\n",
      "Epoch 3: 100%|████████████████████████████████████| 2037/2037 [19:45<00:00,  1.72it/s, loss=0.961, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 8092: 'val_iou_loss' reached 0.27793 (best 0.27793), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=3-step=8092.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  99%|███████████████████████████████████▊| 2023/2037 [19:20<00:08,  1.74it/s, loss=0.959, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████████▊| 2024/2037 [19:24<00:07,  1.74it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████████▊| 2025/2037 [19:26<00:06,  1.74it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████████▊| 2026/2037 [19:27<00:06,  1.74it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▊| 2027/2037 [19:28<00:05,  1.73it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▊| 2028/2037 [19:30<00:05,  1.73it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▊| 2029/2037 [19:31<00:04,  1.73it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2030/2037 [19:32<00:04,  1.73it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2031/2037 [19:34<00:03,  1.73it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2032/2037 [19:35<00:02,  1.73it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2033/2037 [19:36<00:02,  1.73it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2034/2037 [19:37<00:01,  1.73it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2035/2037 [19:39<00:01,  1.73it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████▉| 2036/2037 [19:40<00:00,  1.72it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|████████████████████████████████████| 2037/2037 [19:40<00:00,  1.72it/s, loss=0.959, v_num=ca2u]\u001b[A\n",
      "Epoch 4: 100%|████████████████████████████████████| 2037/2037 [19:40<00:00,  1.72it/s, loss=0.959, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 10115: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  99%|███████████████████████████████████▊| 2023/2037 [19:28<00:08,  1.73it/s, loss=0.946, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████████▊| 2024/2037 [19:33<00:07,  1.73it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████████▊| 2025/2037 [19:34<00:06,  1.72it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████████▊| 2026/2037 [19:35<00:06,  1.72it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▊| 2027/2037 [19:37<00:05,  1.72it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▊| 2028/2037 [19:38<00:05,  1.72it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▊| 2029/2037 [19:39<00:04,  1.72it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2030/2037 [19:41<00:04,  1.72it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2031/2037 [19:42<00:03,  1.72it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2032/2037 [19:43<00:02,  1.72it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2033/2037 [19:45<00:02,  1.72it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2034/2037 [19:46<00:01,  1.71it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2035/2037 [19:47<00:01,  1.71it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████▉| 2036/2037 [19:48<00:00,  1.71it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|████████████████████████████████████| 2037/2037 [19:49<00:00,  1.71it/s, loss=0.946, v_num=ca2u]\u001b[A\n",
      "Epoch 5: 100%|████████████████████████████████████| 2037/2037 [19:49<00:00,  1.71it/s, loss=0.946, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 12138: 'val_iou_loss' reached 0.26721 (best 0.26721), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=5-step=12138.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  99%|███████████████████████████████████▊| 2023/2037 [19:38<00:08,  1.72it/s, loss=0.953, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  99%|███████████████████████████████████▊| 2024/2037 [19:43<00:07,  1.71it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6:  99%|███████████████████████████████████▊| 2025/2037 [19:44<00:07,  1.71it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6:  99%|███████████████████████████████████▊| 2026/2037 [19:45<00:06,  1.71it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▊| 2027/2037 [19:47<00:05,  1.71it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▊| 2028/2037 [19:48<00:05,  1.71it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▊| 2029/2037 [19:49<00:04,  1.71it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2030/2037 [19:50<00:04,  1.70it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2031/2037 [19:52<00:03,  1.70it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2032/2037 [19:53<00:02,  1.70it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2033/2037 [19:54<00:02,  1.70it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2034/2037 [19:56<00:01,  1.70it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2035/2037 [19:57<00:01,  1.70it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████▉| 2036/2037 [19:58<00:00,  1.70it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|████████████████████████████████████| 2037/2037 [19:58<00:00,  1.70it/s, loss=0.953, v_num=ca2u]\u001b[A\n",
      "Epoch 6: 100%|████████████████████████████████████| 2037/2037 [19:58<00:00,  1.70it/s, loss=0.953, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 14161: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  99%|███████████████████████████████████▊| 2023/2037 [19:31<00:08,  1.73it/s, loss=0.912, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  99%|███████████████████████████████████▊| 2024/2037 [19:35<00:07,  1.72it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7:  99%|███████████████████████████████████▊| 2025/2037 [19:36<00:06,  1.72it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7:  99%|███████████████████████████████████▊| 2026/2037 [19:38<00:06,  1.72it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▊| 2027/2037 [19:39<00:05,  1.72it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▊| 2028/2037 [19:40<00:05,  1.72it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▊| 2029/2037 [19:41<00:04,  1.72it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2030/2037 [19:43<00:04,  1.72it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2031/2037 [19:44<00:03,  1.71it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2032/2037 [19:46<00:02,  1.71it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2033/2037 [19:47<00:02,  1.71it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2034/2037 [19:48<00:01,  1.71it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2035/2037 [19:50<00:01,  1.71it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████▉| 2036/2037 [19:51<00:00,  1.71it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|████████████████████████████████████| 2037/2037 [19:51<00:00,  1.71it/s, loss=0.912, v_num=ca2u]\u001b[A\n",
      "Epoch 7: 100%|████████████████████████████████████| 2037/2037 [19:51<00:00,  1.71it/s, loss=0.912, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 16184: 'val_iou_loss' reached 0.25548 (best 0.25548), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=7-step=16184.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  99%|███████████████████████████████████▊| 2023/2037 [19:30<00:08,  1.73it/s, loss=0.969, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  99%|███████████████████████████████████▊| 2024/2037 [19:35<00:07,  1.72it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8:  99%|███████████████████████████████████▊| 2025/2037 [19:36<00:06,  1.72it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8:  99%|███████████████████████████████████▊| 2026/2037 [19:38<00:06,  1.72it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▊| 2027/2037 [19:39<00:05,  1.72it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▊| 2028/2037 [19:40<00:05,  1.72it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▊| 2029/2037 [19:42<00:04,  1.72it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2030/2037 [19:43<00:04,  1.72it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2031/2037 [19:44<00:03,  1.71it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2032/2037 [19:45<00:02,  1.71it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2033/2037 [19:47<00:02,  1.71it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2034/2037 [19:48<00:01,  1.71it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2035/2037 [19:49<00:01,  1.71it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████▉| 2036/2037 [19:51<00:00,  1.71it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|████████████████████████████████████| 2037/2037 [19:51<00:00,  1.71it/s, loss=0.969, v_num=ca2u]\u001b[A\n",
      "Epoch 8: 100%|████████████████████████████████████| 2037/2037 [19:51<00:00,  1.71it/s, loss=0.969, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 18207: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  99%|███████████████████████████████████▊| 2023/2037 [19:43<00:08,  1.71it/s, loss=0.983, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  99%|███████████████████████████████████▊| 2024/2037 [19:48<00:07,  1.70it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9:  99%|███████████████████████████████████▊| 2025/2037 [19:49<00:07,  1.70it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9:  99%|███████████████████████████████████▊| 2026/2037 [19:51<00:06,  1.70it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▊| 2027/2037 [19:52<00:05,  1.70it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▊| 2028/2037 [19:53<00:05,  1.70it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▊| 2029/2037 [19:55<00:04,  1.70it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2030/2037 [19:56<00:04,  1.70it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2031/2037 [19:57<00:03,  1.70it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2032/2037 [19:59<00:02,  1.69it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2033/2037 [20:00<00:02,  1.69it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2034/2037 [20:01<00:01,  1.69it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2035/2037 [20:03<00:01,  1.69it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████▉| 2036/2037 [20:04<00:00,  1.69it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|████████████████████████████████████| 2037/2037 [20:04<00:00,  1.69it/s, loss=0.983, v_num=ca2u]\u001b[A\n",
      "Epoch 9: 100%|████████████████████████████████████| 2037/2037 [20:04<00:00,  1.69it/s, loss=0.983, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 20230: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  99%|██████████████████████████████████▊| 2023/2037 [19:57<00:08,  1.69it/s, loss=0.948, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  99%|██████████████████████████████████▊| 2024/2037 [20:02<00:07,  1.68it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10:  99%|██████████████████████████████████▊| 2025/2037 [20:03<00:07,  1.68it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10:  99%|██████████████████████████████████▊| 2026/2037 [20:04<00:06,  1.68it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▊| 2027/2037 [20:06<00:05,  1.68it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▊| 2028/2037 [20:07<00:05,  1.68it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▊| 2029/2037 [20:08<00:04,  1.68it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2030/2037 [20:10<00:04,  1.68it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2031/2037 [20:11<00:03,  1.68it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2032/2037 [20:12<00:02,  1.68it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2033/2037 [20:14<00:02,  1.67it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2034/2037 [20:15<00:01,  1.67it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2035/2037 [20:16<00:01,  1.67it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████▉| 2036/2037 [20:17<00:00,  1.67it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|███████████████████████████████████| 2037/2037 [20:18<00:00,  1.67it/s, loss=0.948, v_num=ca2u]\u001b[A\n",
      "Epoch 10: 100%|███████████████████████████████████| 2037/2037 [20:18<00:00,  1.67it/s, loss=0.948, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 22253: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 11:  99%|███████████████████████████████████▊| 2023/2037 [19:47<00:08,  1.70it/s, loss=0.95, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  99%|███████████████████████████████████▊| 2024/2037 [19:52<00:07,  1.70it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11:  99%|███████████████████████████████████▊| 2025/2037 [19:53<00:07,  1.70it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11:  99%|███████████████████████████████████▊| 2026/2037 [19:54<00:06,  1.70it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▊| 2027/2037 [19:56<00:05,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▊| 2028/2037 [19:57<00:05,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▊| 2029/2037 [19:58<00:04,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▉| 2030/2037 [20:00<00:04,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▉| 2031/2037 [20:01<00:03,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▉| 2032/2037 [20:02<00:02,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▉| 2033/2037 [20:04<00:02,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▉| 2034/2037 [20:05<00:01,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▉| 2035/2037 [20:06<00:01,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████▉| 2036/2037 [20:07<00:00,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|████████████████████████████████████| 2037/2037 [20:08<00:00,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A\n",
      "Epoch 11: 100%|████████████████████████████████████| 2037/2037 [20:08<00:00,  1.69it/s, loss=0.95, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 24276: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  99%|██████████████████████████████████▊| 2023/2037 [20:04<00:08,  1.68it/s, loss=0.945, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  99%|██████████████████████████████████▊| 2024/2037 [20:09<00:07,  1.67it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12:  99%|██████████████████████████████████▊| 2025/2037 [20:10<00:07,  1.67it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12:  99%|██████████████████████████████████▊| 2026/2037 [20:11<00:06,  1.67it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▊| 2027/2037 [20:13<00:05,  1.67it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▊| 2028/2037 [20:14<00:05,  1.67it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▊| 2029/2037 [20:15<00:04,  1.67it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2030/2037 [20:17<00:04,  1.67it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2031/2037 [20:18<00:03,  1.67it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2032/2037 [20:19<00:03,  1.67it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2033/2037 [20:21<00:02,  1.66it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2034/2037 [20:22<00:01,  1.66it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2035/2037 [20:23<00:01,  1.66it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████▉| 2036/2037 [20:25<00:00,  1.66it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|███████████████████████████████████| 2037/2037 [20:25<00:00,  1.66it/s, loss=0.945, v_num=ca2u]\u001b[A\n",
      "Epoch 12: 100%|███████████████████████████████████| 2037/2037 [20:25<00:00,  1.66it/s, loss=0.945, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 26299: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  99%|██████████████████████████████████▊| 2023/2037 [19:58<00:08,  1.69it/s, loss=0.926, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  99%|██████████████████████████████████▊| 2024/2037 [20:03<00:07,  1.68it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13:  99%|██████████████████████████████████▊| 2025/2037 [20:04<00:07,  1.68it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13:  99%|██████████████████████████████████▊| 2026/2037 [20:05<00:06,  1.68it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▊| 2027/2037 [20:07<00:05,  1.68it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▊| 2028/2037 [20:08<00:05,  1.68it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▊| 2029/2037 [20:09<00:04,  1.68it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2030/2037 [20:11<00:04,  1.68it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2031/2037 [20:12<00:03,  1.68it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2032/2037 [20:13<00:02,  1.67it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2033/2037 [20:15<00:02,  1.67it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2034/2037 [20:16<00:01,  1.67it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2035/2037 [20:17<00:01,  1.67it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████▉| 2036/2037 [20:19<00:00,  1.67it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|███████████████████████████████████| 2037/2037 [20:19<00:00,  1.67it/s, loss=0.926, v_num=ca2u]\u001b[A\n",
      "Epoch 13: 100%|███████████████████████████████████| 2037/2037 [20:19<00:00,  1.67it/s, loss=0.926, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 28322: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 14:  99%|██████████████████████████████████▊| 2023/2037 [19:49<00:08,  1.70it/s, loss=0.901, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  99%|██████████████████████████████████▊| 2024/2037 [19:54<00:07,  1.69it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14:  99%|██████████████████████████████████▊| 2025/2037 [19:55<00:07,  1.69it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14:  99%|██████████████████████████████████▊| 2026/2037 [19:57<00:06,  1.69it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▊| 2027/2037 [19:58<00:05,  1.69it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▊| 2028/2037 [19:59<00:05,  1.69it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▊| 2029/2037 [20:01<00:04,  1.69it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2030/2037 [20:02<00:04,  1.69it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2031/2037 [20:03<00:03,  1.69it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2032/2037 [20:05<00:02,  1.69it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2033/2037 [20:06<00:02,  1.68it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2034/2037 [20:07<00:01,  1.68it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2035/2037 [20:09<00:01,  1.68it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████▉| 2036/2037 [20:10<00:00,  1.68it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|███████████████████████████████████| 2037/2037 [20:10<00:00,  1.68it/s, loss=0.901, v_num=ca2u]\u001b[A\n",
      "Epoch 14: 100%|███████████████████████████████████| 2037/2037 [20:10<00:00,  1.68it/s, loss=0.901, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 30345: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  99%|███████████████████████████████████▊| 2023/2037 [19:50<00:08,  1.70it/s, loss=0.91, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  99%|███████████████████████████████████▊| 2024/2037 [19:54<00:07,  1.69it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15:  99%|███████████████████████████████████▊| 2025/2037 [19:56<00:07,  1.69it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15:  99%|███████████████████████████████████▊| 2026/2037 [19:57<00:06,  1.69it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▊| 2027/2037 [19:58<00:05,  1.69it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▊| 2028/2037 [20:00<00:05,  1.69it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▊| 2029/2037 [20:01<00:04,  1.69it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▉| 2030/2037 [20:02<00:04,  1.69it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▉| 2031/2037 [20:04<00:03,  1.69it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▉| 2032/2037 [20:05<00:02,  1.69it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▉| 2033/2037 [20:06<00:02,  1.68it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▉| 2034/2037 [20:08<00:01,  1.68it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▉| 2035/2037 [20:09<00:01,  1.68it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████▉| 2036/2037 [20:10<00:00,  1.68it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|████████████████████████████████████| 2037/2037 [20:11<00:00,  1.68it/s, loss=0.91, v_num=ca2u]\u001b[A\n",
      "Epoch 15: 100%|████████████████████████████████████| 2037/2037 [20:11<00:00,  1.68it/s, loss=0.91, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 32368: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  99%|██████████████████████████████████▊| 2023/2037 [19:56<00:08,  1.69it/s, loss=0.918, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  99%|██████████████████████████████████▊| 2024/2037 [20:00<00:07,  1.69it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16:  99%|██████████████████████████████████▊| 2025/2037 [20:02<00:07,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16:  99%|██████████████████████████████████▊| 2026/2037 [20:03<00:06,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▊| 2027/2037 [20:04<00:05,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▊| 2028/2037 [20:05<00:05,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▊| 2029/2037 [20:07<00:04,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2030/2037 [20:08<00:04,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2031/2037 [20:10<00:03,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2032/2037 [20:11<00:02,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2033/2037 [20:12<00:02,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2034/2037 [20:14<00:01,  1.68it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2035/2037 [20:15<00:01,  1.67it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████▉| 2036/2037 [20:16<00:00,  1.67it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|███████████████████████████████████| 2037/2037 [20:16<00:00,  1.67it/s, loss=0.918, v_num=ca2u]\u001b[A\n",
      "Epoch 16: 100%|███████████████████████████████████| 2037/2037 [20:16<00:00,  1.67it/s, loss=0.918, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 34391: 'val_iou_loss' reached 0.25159 (best 0.25159), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=16-step=34391.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  99%|██████████████████████████████████▊| 2023/2037 [20:18<00:08,  1.66it/s, loss=0.886, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  99%|██████████████████████████████████▊| 2024/2037 [20:23<00:07,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17:  99%|██████████████████████████████████▊| 2025/2037 [20:24<00:07,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17:  99%|██████████████████████████████████▊| 2026/2037 [20:25<00:06,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▊| 2027/2037 [20:27<00:06,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▊| 2028/2037 [20:28<00:05,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▊| 2029/2037 [20:29<00:04,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2030/2037 [20:30<00:04,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2031/2037 [20:32<00:03,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2032/2037 [20:33<00:03,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2033/2037 [20:34<00:02,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2034/2037 [20:36<00:01,  1.65it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2035/2037 [20:37<00:01,  1.64it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████▉| 2036/2037 [20:38<00:00,  1.64it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|███████████████████████████████████| 2037/2037 [20:39<00:00,  1.64it/s, loss=0.886, v_num=ca2u]\u001b[A\n",
      "Epoch 17: 100%|███████████████████████████████████| 2037/2037 [20:39<00:00,  1.64it/s, loss=0.886, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 36414: 'val_iou_loss' reached 0.24951 (best 0.24951), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=17-step=36414.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  99%|██████████████████████████████████▊| 2023/2037 [20:37<00:08,  1.64it/s, loss=0.884, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  99%|██████████████████████████████████▊| 2024/2037 [20:41<00:07,  1.63it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18:  99%|██████████████████████████████████▊| 2025/2037 [20:43<00:07,  1.63it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18:  99%|██████████████████████████████████▊| 2026/2037 [20:44<00:06,  1.63it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▊| 2027/2037 [20:45<00:06,  1.63it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▊| 2028/2037 [20:47<00:05,  1.63it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▊| 2029/2037 [20:48<00:04,  1.63it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2030/2037 [20:49<00:04,  1.62it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2031/2037 [20:51<00:03,  1.62it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2032/2037 [20:52<00:03,  1.62it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2033/2037 [20:53<00:02,  1.62it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2034/2037 [20:55<00:01,  1.62it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2035/2037 [20:56<00:01,  1.62it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████▉| 2036/2037 [20:57<00:00,  1.62it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|███████████████████████████████████| 2037/2037 [20:58<00:00,  1.62it/s, loss=0.884, v_num=ca2u]\u001b[A\n",
      "Epoch 18: 100%|███████████████████████████████████| 2037/2037 [20:58<00:00,  1.62it/s, loss=0.884, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 38437: 'val_iou_loss' was not in top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  99%|██████████████████████████████████▊| 2023/2037 [20:13<00:08,  1.67it/s, loss=0.911, v_num=ca2u]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                      | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                         | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  99%|██████████████████████████████████▊| 2024/2037 [20:17<00:07,  1.66it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19:  99%|██████████████████████████████████▊| 2025/2037 [20:18<00:07,  1.66it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19:  99%|██████████████████████████████████▊| 2026/2037 [20:20<00:06,  1.66it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▊| 2027/2037 [20:21<00:06,  1.66it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▊| 2028/2037 [20:23<00:05,  1.66it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▊| 2029/2037 [20:24<00:04,  1.66it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2030/2037 [20:25<00:04,  1.66it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2031/2037 [20:27<00:03,  1.66it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2032/2037 [20:28<00:03,  1.65it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2033/2037 [20:29<00:02,  1.65it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2034/2037 [20:31<00:01,  1.65it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2035/2037 [20:32<00:01,  1.65it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████▉| 2036/2037 [20:33<00:00,  1.65it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|███████████████████████████████████| 2037/2037 [20:33<00:00,  1.65it/s, loss=0.911, v_num=ca2u]\u001b[A\n",
      "Epoch 19: 100%|███████████████████████████████████| 2037/2037 [20:33<00:00,  1.65it/s, loss=0.911, v_num=ca2u]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 40460: 'val_iou_loss' reached 0.24900 (best 0.24900), saving model to '/home/viplab/VipLabProjects/satellite-knowledge-distillation/train_models/training_flooding_bgri/checkpoint/epoch=19-step=40460.ckpt' as top True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  26%|█████████▎                          | 526/2037 [05:25<15:35,  1.62it/s, loss=0.916, v_num=ca2u]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_train[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3eb6095c-4b3f-47db-8920-92242e50f36b",
   "metadata": {},
   "source": [
    "n_images=10\n",
    "fig, axs = plt.subplots(4, n_images, figsize=(18,14),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.max_tile_size = config.model_params.hyperparameters.max_tile_size\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "# import torch\n",
    "import numpy as np\n",
    "from ml4floods.models.utils import metrics\n",
    "from ml4floods.models.model_setup import get_model_inference_function\n",
    "import pandas as pd\n",
    "\n",
    "# model.to(\"cuda\")\n",
    "inference_function = get_model_inference_function(model, config, apply_normalization=False, activation=\"softmax\")\n",
    "\n",
    "# dataset2 = get_dataset(config.data_params)\n",
    "dl = dataset.val_dataloader() # pytorch Dataloader\n",
    "print(str(dl.batch_size))\n",
    "\n",
    "# Otherwise fails when reading test dataset from remote bucket\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "thresholds_water = [0,1e-3,1e-2]+np.arange(0.5,.96,.05).tolist() + [.99,.995,.999]\n",
    "\n",
    "mets = metrics.compute_metrics(\n",
    "    dl,\n",
    "    inference_function, \n",
    "    thresholds_water=thresholds_water, \n",
    "    plot=False, convert_targets=False)\n",
    "\n",
    "label_names = [\"land\", \"water\", \"cloud\"]\n",
    "metrics.plot_metrics(mets, label_names)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9f8d76e-a1fc-456e-b3f9-8e53d0da13a0",
   "metadata": {},
   "source": [
    "train_fc_loss = model.train_fc_loss\n",
    "train_iou_loss = model.train_iou_loss\n",
    "train_compound_loss = model.train_compound_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(dl.dataset, \"image_files\"):\n",
    "    cems_code = [os.path.basename(f).split(\"_\")[0] for f in dl.dataset.image_files]\n",
    "else:\n",
    "    cems_code = [os.path.basename(f.file_name).split(\"_\")[0] for f in dl.dataset.list_of_windows]\n",
    "\n",
    "iou_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_iou,\n",
    "                                                    label_names=[f\"IoU_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "recall_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_recall,\n",
    "                                                       label_names=[f\"Recall_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "join_data_per_code = pd.merge(recall_per_code,iou_per_code,on=\"code\")\n",
    "join_data_per_code = join_data_per_code.set_index(\"code\")\n",
    "join_data_per_code = join_data_per_code*100\n",
    "print(f\"Mean values across flood events: {join_data_per_code.mean(axis=0).to_dict()}\")\n",
    "join_data_per_code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6233dfa4-7736-4f55-a3a1-ca90f6bd8944",
   "metadata": {},
   "source": [
    "# import torch\n",
    "from pytorch_lightning.utilities.cloud_io import atomic_save\n",
    "from ml4floods.models.config_setup import save_json\n",
    "\n",
    "# Save in the cloud and in the wandb logger save dir\n",
    "atomic_save(model.state_dict(), f\"{experiment_path}/model_irirnir_worldflood_model_1_epoch_2_gamma_5_alpha_0_001.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config_model_irirnir_worldflood_model_1_epoch_2_gamma_5_alpha_0_001.pt.json\"\n",
    "save_json(config, config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b6829-07cf-4831-b114-20230d3b3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f\"{experiment_path}/model_irirnir_worldflood_model_1_epoch_2_adaptive_gamma_alpha_0_001.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config_irirnir_worldflood_model_1_epoch_2_adaptive_gamma_alpha_0_001.json\"\n",
    "import json\n",
    "with open(config_file_path, 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "758117e6-21fd-4c87-bcf9-e62a944e0930",
   "metadata": {},
   "source": [
    "print(wandb_logger)\n",
    "if setup_weights_and_biases:\n",
    "    torch.save(model.state_dict(), os.path.join(wandb_logger.save_dir, 'model_irirnir_worldflood_model_1_epoch_2_adaptive_gamma_alpha_0_001.pt'))\n",
    "    wandb.save(os.path.join(wandb_logger.save_dir, 'model_irirnir_worldflood_model_1_epoch_2_adaptive_gamma_alpha_0_001.pt')) # Copy weights to weights and biases server\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f5845-b502-41df-afdb-df2af60b5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the images shown before\n",
    "\n",
    "logits = model(batch_val[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbafaab-0986-4de8-98ef-0bfb21c439d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image_start=7\n",
    "n_images=14\n",
    "count=int(n_images-n_image_start)\n",
    "fig, axs = plt.subplots(4, count, figsize=(18,14),tight_layout=True)\n",
    "importlib.reload(flooding_model)\n",
    "flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"bgri\",axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"bgri\",bands_show=[\"B8\",\"B8\", \"B8\"],axs=axs[1],max_clip_val=3500.)\n",
    "# flooding_model.plot_batch(batch_val[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_val[\"mask\"][n_image_start:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[n_image_start:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12baf379-1262-4e0a-94ae-b0e365443a99",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (pt-gpu)",
   "language": "python",
   "name": "pt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
